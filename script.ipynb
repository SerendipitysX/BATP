{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Read data from a file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data\n",
    "\n",
    "\n",
    "def convert_str_to_list(line):\n",
    "    \"\"\"\n",
    "    Convert string to list.\n",
    "    \"\"\"\n",
    "    return json.loads(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (345,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [43]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m read_data(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD:/A-bus/bus_pytorch/data/dataset/train.txt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      2\u001B[0m data \u001B[38;5;241m=\u001B[39m [convert_str_to_list(line) \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m data]\n\u001B[1;32m----> 3\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (345,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "data = read_data('D:/A-bus/bus_pytorch/data/dataset/train.txt')\n",
    "data = [convert_str_to_list(line) for line in data]\n",
    "data = np.array(data)\n",
    "data[0].shape\n",
    "# l = np.array(l)\n",
    "# max_len = 50\n",
    "# route_len = int(len(l)/30)\n",
    "# l = l.reshape(30, route_len)\n",
    "# l = torch.Tensor(l)\n",
    "# print(l.shape)\n",
    "# l = F.pad(input=l, pad=(0, max_len-route_len, 0, 0), mode='constant', value=0)\n",
    "# print(l.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 27])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_conv = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=(3), padding=0)\n",
    "x = torch.randn(16, 1, 29, 50)\n",
    "# for i in range (16):\n",
    "#     x[i] = F.pad(input=x[i], pad=(0, 0, 0, 0), mode='constant', value=0)\n",
    "#     x[i] = causal_conv(x[i])\n",
    "#     print(x[i].shape)\n",
    "causal_conv(x[0,:,:, 0]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 29])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(16, 1, 29, 50)\n",
    "x[0,:,:, 0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def t2v(tau, f, out_features, w, b, w0, b0, arg=None):\n",
    "    if arg:\n",
    "        v1 = f(torch.matmul(tau, w) + b, arg)\n",
    "    else:\n",
    "        #print(w.shape, t1.shape, b.shape)\n",
    "        v1 = f(torch.matmul(tau, w) + b)\n",
    "        print('v1:', v1.shape)\n",
    "    v2 = torch.matmul(tau, w0) + b0\n",
    "    print('v2:',v2.shape)\n",
    "    return torch.cat([v1, v2], 1)\n",
    "\n",
    "class SineActivation(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SineActivation, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.w0 = nn.parameter.Parameter(torch.randn(in_features, 1))\n",
    "        self.b0 = nn.parameter.Parameter(torch.randn(1))\n",
    "        self.w = nn.parameter.Parameter(torch.randn(in_features, out_features-1))\n",
    "        self.b = nn.parameter.Parameter(torch.randn(out_features-1))\n",
    "        self.f = torch.sin\n",
    "\n",
    "    def forward(self, tau):\n",
    "        return t2v(tau, self.f, self.out_features, self.w, self.b, self.w0, self.b0)\n",
    "\n",
    "class CosineActivation(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CosineActivation, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.w0 = nn.parameter.Parameter(torch.randn(in_features, 1))\n",
    "        self.b0 = nn.parameter.Parameter(torch.randn(1))\n",
    "        self.w = nn.parameter.Parameter(torch.randn(in_features, out_features-1))\n",
    "        self.b = nn.parameter.Parameter(torch.randn(out_features-1))\n",
    "        self.f = torch.cos\n",
    "\n",
    "    def forward(self, tau):\n",
    "        return t2v(tau, self.f, self.out_features, self.w, self.b, self.w0, self.b0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: torch.Size([1, 63])\n",
      "v2: torch.Size([1, 1])\n",
      "torch.Size([1, 64])\n",
      "v1: torch.Size([1, 63])\n",
      "v2: torch.Size([1, 1])\n",
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "sineact = SineActivation(1, 64)\n",
    "cosact = CosineActivation(1, 64)\n",
    "\n",
    "print(sineact(torch.Tensor([[7]])).shape)\n",
    "print(cosact(torch.Tensor([[7]])).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.9098,  0.7401,  0.6955, -0.9861,  0.7383,  0.8965,  0.5066, -0.2459,\n         -0.4764,  0.1394, -0.8101, -0.4006, -0.0696,  0.3543,  0.0761,  0.5986,\n          0.1463, -0.2179, -0.6638,  0.6862,  0.8209,  0.9999,  0.2062, -0.3347,\n         -0.9476, -0.8814,  0.1271, -0.9184,  0.7954, -0.8993, -1.0000, -0.9898,\n          0.9873,  0.9461,  0.8175, -0.9950,  0.9294,  0.9425, -0.8157,  0.7968,\n         -0.5311,  0.9614,  0.9470, -0.5990,  0.6272,  0.6897,  0.9307, -0.8034,\n          0.5433, -0.9946,  0.7017,  0.5916, -0.4506, -0.8020,  0.5983,  0.0486,\n          0.5446,  0.9905, -0.0303,  0.2498,  0.9485,  0.6191,  0.2212, 10.2144]],\n       grad_fn=<CatBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sineact(torch.Tensor([[7]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8603])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((1))\n",
    "b = torch.randn((1))\n",
    "c = torch.mul(a, b)\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]) tensor([[-0.9848]]) tensor([[-0.9848],\n",
      "        [-0.9848],\n",
      "        [-0.9848],\n",
      "        [-0.9848]])\n",
      "torch.Size([4, 1]) torch.Size([1, 1]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((4,1))\n",
    "b = torch.randn((1,1))\n",
    "c = torch.mul(a, b)\n",
    "print(a,b,c)\n",
    "print(a.shape, b.shape, c.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]]) tensor([[[ 1.8683, -0.8744,  1.9455,  1.0013, -0.6271,  0.1458, -0.1026]],\n",
      "\n",
      "        [[ 2.3816, -1.9624, -2.3535,  0.0988,  3.1183,  0.1993,  1.1589]],\n",
      "\n",
      "        [[ 0.2284, -0.3128, -0.8863,  0.9559,  1.2712, -0.4170,  0.0057]]]) tensor([[[ 1.8683, -0.8744,  1.9455,  1.0013, -0.6271,  0.1458, -0.1026],\n",
      "         [ 1.8683, -0.8744,  1.9455,  1.0013, -0.6271,  0.1458, -0.1026],\n",
      "         [ 1.8683, -0.8744,  1.9455,  1.0013, -0.6271,  0.1458, -0.1026],\n",
      "         [ 1.8683, -0.8744,  1.9455,  1.0013, -0.6271,  0.1458, -0.1026]],\n",
      "\n",
      "        [[ 2.3816, -1.9624, -2.3535,  0.0988,  3.1183,  0.1993,  1.1589],\n",
      "         [ 2.3816, -1.9624, -2.3535,  0.0988,  3.1183,  0.1993,  1.1589],\n",
      "         [ 2.3816, -1.9624, -2.3535,  0.0988,  3.1183,  0.1993,  1.1589],\n",
      "         [ 2.3816, -1.9624, -2.3535,  0.0988,  3.1183,  0.1993,  1.1589]],\n",
      "\n",
      "        [[ 0.2284, -0.3128, -0.8863,  0.9559,  1.2712, -0.4170,  0.0057],\n",
      "         [ 0.2284, -0.3128, -0.8863,  0.9559,  1.2712, -0.4170,  0.0057],\n",
      "         [ 0.2284, -0.3128, -0.8863,  0.9559,  1.2712, -0.4170,  0.0057],\n",
      "         [ 0.2284, -0.3128, -0.8863,  0.9559,  1.2712, -0.4170,  0.0057]]])\n",
      "torch.Size([3, 4, 1]) torch.Size([3, 1, 7]) torch.Size([3, 4, 7])\n"
     ]
    }
   ],
   "source": [
    "# a = torch.ones((4,3))\n",
    "# b = torch.randn((1,3))\n",
    "# c = torch.mul(a, b)\n",
    "# print(a,b,c)\n",
    "# print(a.shape, b.shape, c.shape)\n",
    "\n",
    "a = torch.ones((3,4,1))\n",
    "b = torch.randn((3,1,7))\n",
    "c = torch.mul(a, b)\n",
    "print(a,b,c)\n",
    "print(a.shape, b.shape, c.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3]) torch.Size([2, 1, 3]) torch.Size([2, 4, 3])\n",
      "tensor([[[ 0.4222, -1.5881,  0.8632],\n",
      "         [ 0.4222, -1.5881,  0.8632],\n",
      "         [ 0.4222, -1.5881,  0.8632],\n",
      "         [ 0.4222, -1.5881,  0.8632]],\n",
      "\n",
      "        [[-2.5318,  0.5178,  0.1337],\n",
      "         [-2.5318,  0.5178,  0.1337],\n",
      "         [-2.5318,  0.5178,  0.1337],\n",
      "         [-2.5318,  0.5178,  0.1337]]])\n",
      "torch.Size([2, 3, 4, 1]) torch.Size([2, 3, 1, 7]) torch.Size([2, 3, 4, 7])\n",
      "tensor([[[[ 0.6064, -0.4609, -2.3317,  1.4858, -2.0842, -0.2221,  1.2128],\n",
      "          [ 0.6064, -0.4609, -2.3317,  1.4858, -2.0842, -0.2221,  1.2128],\n",
      "          [ 0.6064, -0.4609, -2.3317,  1.4858, -2.0842, -0.2221,  1.2128],\n",
      "          [ 0.6064, -0.4609, -2.3317,  1.4858, -2.0842, -0.2221,  1.2128]],\n",
      "\n",
      "         [[ 0.2640, -1.1525,  0.2152, -2.1817, -0.9160, -0.4981,  1.3182],\n",
      "          [ 0.2640, -1.1525,  0.2152, -2.1817, -0.9160, -0.4981,  1.3182],\n",
      "          [ 0.2640, -1.1525,  0.2152, -2.1817, -0.9160, -0.4981,  1.3182],\n",
      "          [ 0.2640, -1.1525,  0.2152, -2.1817, -0.9160, -0.4981,  1.3182]],\n",
      "\n",
      "         [[-0.3892,  1.2774,  0.9456, -1.7363, -0.1341,  0.0660,  0.4617],\n",
      "          [-0.3892,  1.2774,  0.9456, -1.7363, -0.1341,  0.0660,  0.4617],\n",
      "          [-0.3892,  1.2774,  0.9456, -1.7363, -0.1341,  0.0660,  0.4617],\n",
      "          [-0.3892,  1.2774,  0.9456, -1.7363, -0.1341,  0.0660,  0.4617]]],\n",
      "\n",
      "\n",
      "        [[[-0.6342, -0.2295,  0.7309, -1.2196, -0.2906, -0.9478,  1.6055],\n",
      "          [-0.6342, -0.2295,  0.7309, -1.2196, -0.2906, -0.9478,  1.6055],\n",
      "          [-0.6342, -0.2295,  0.7309, -1.2196, -0.2906, -0.9478,  1.6055],\n",
      "          [-0.6342, -0.2295,  0.7309, -1.2196, -0.2906, -0.9478,  1.6055]],\n",
      "\n",
      "         [[-1.3623, -0.9967,  0.2425, -0.6552,  1.3466,  1.7313,  0.8463],\n",
      "          [-1.3623, -0.9967,  0.2425, -0.6552,  1.3466,  1.7313,  0.8463],\n",
      "          [-1.3623, -0.9967,  0.2425, -0.6552,  1.3466,  1.7313,  0.8463],\n",
      "          [-1.3623, -0.9967,  0.2425, -0.6552,  1.3466,  1.7313,  0.8463]],\n",
      "\n",
      "         [[ 0.6118, -1.9446, -0.2214, -0.9507,  0.3212, -0.3172,  0.2192],\n",
      "          [ 0.6118, -1.9446, -0.2214, -0.9507,  0.3212, -0.3172,  0.2192],\n",
      "          [ 0.6118, -1.9446, -0.2214, -0.9507,  0.3212, -0.3172,  0.2192],\n",
      "          [ 0.6118, -1.9446, -0.2214, -0.9507,  0.3212, -0.3172,  0.2192]]]])\n",
      "torch.Size([2, 3, 4, 1]) torch.Size([2, 3, 4, 7])\n",
      "--------\n",
      "tensor([[[[ 0.4222,  0.6064, -0.4609, -2.3317,  1.4858, -2.0842, -0.2221,\n",
      "            1.2128],\n",
      "          [ 0.4222,  0.6064, -0.4609, -2.3317,  1.4858, -2.0842, -0.2221,\n",
      "            1.2128],\n",
      "          [ 0.4222,  0.6064, -0.4609, -2.3317,  1.4858, -2.0842, -0.2221,\n",
      "            1.2128],\n",
      "          [ 0.4222,  0.6064, -0.4609, -2.3317,  1.4858, -2.0842, -0.2221,\n",
      "            1.2128]],\n",
      "\n",
      "         [[-1.5881,  0.2640, -1.1525,  0.2152, -2.1817, -0.9160, -0.4981,\n",
      "            1.3182],\n",
      "          [-1.5881,  0.2640, -1.1525,  0.2152, -2.1817, -0.9160, -0.4981,\n",
      "            1.3182],\n",
      "          [-1.5881,  0.2640, -1.1525,  0.2152, -2.1817, -0.9160, -0.4981,\n",
      "            1.3182],\n",
      "          [-1.5881,  0.2640, -1.1525,  0.2152, -2.1817, -0.9160, -0.4981,\n",
      "            1.3182]],\n",
      "\n",
      "         [[ 0.8632, -0.3892,  1.2774,  0.9456, -1.7363, -0.1341,  0.0660,\n",
      "            0.4617],\n",
      "          [ 0.8632, -0.3892,  1.2774,  0.9456, -1.7363, -0.1341,  0.0660,\n",
      "            0.4617],\n",
      "          [ 0.8632, -0.3892,  1.2774,  0.9456, -1.7363, -0.1341,  0.0660,\n",
      "            0.4617],\n",
      "          [ 0.8632, -0.3892,  1.2774,  0.9456, -1.7363, -0.1341,  0.0660,\n",
      "            0.4617]]],\n",
      "\n",
      "\n",
      "        [[[-2.5318, -0.6342, -0.2295,  0.7309, -1.2196, -0.2906, -0.9478,\n",
      "            1.6055],\n",
      "          [-2.5318, -0.6342, -0.2295,  0.7309, -1.2196, -0.2906, -0.9478,\n",
      "            1.6055],\n",
      "          [-2.5318, -0.6342, -0.2295,  0.7309, -1.2196, -0.2906, -0.9478,\n",
      "            1.6055],\n",
      "          [-2.5318, -0.6342, -0.2295,  0.7309, -1.2196, -0.2906, -0.9478,\n",
      "            1.6055]],\n",
      "\n",
      "         [[ 0.5178, -1.3623, -0.9967,  0.2425, -0.6552,  1.3466,  1.7313,\n",
      "            0.8463],\n",
      "          [ 0.5178, -1.3623, -0.9967,  0.2425, -0.6552,  1.3466,  1.7313,\n",
      "            0.8463],\n",
      "          [ 0.5178, -1.3623, -0.9967,  0.2425, -0.6552,  1.3466,  1.7313,\n",
      "            0.8463],\n",
      "          [ 0.5178, -1.3623, -0.9967,  0.2425, -0.6552,  1.3466,  1.7313,\n",
      "            0.8463]],\n",
      "\n",
      "         [[ 0.1337,  0.6118, -1.9446, -0.2214, -0.9507,  0.3212, -0.3172,\n",
      "            0.2192],\n",
      "          [ 0.1337,  0.6118, -1.9446, -0.2214, -0.9507,  0.3212, -0.3172,\n",
      "            0.2192],\n",
      "          [ 0.1337,  0.6118, -1.9446, -0.2214, -0.9507,  0.3212, -0.3172,\n",
      "            0.2192],\n",
      "          [ 0.1337,  0.6118, -1.9446, -0.2214, -0.9507,  0.3212, -0.3172,\n",
      "            0.2192]]]])\n",
      "torch.Size([2, 3, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2,4,3))# bz, days, stations\n",
    "b = torch.randn((2,1,3))\n",
    "c1 = torch.mul(a, b) # 2,4,3\n",
    "print(a.shape, b.shape, c1.shape)\n",
    "print(c1)\n",
    "\n",
    "a = torch.ones((2,4,3)) # bz, days, stations\n",
    "a = a.permute(0,2,1) # bz, stations, days\n",
    "a = a.unsqueeze(-1) # bz, stations, days, 1\n",
    "b = torch.randn((2,3,1,7))\n",
    "c2 = torch.mul(a, b)  # 2,3,4,7\n",
    "print(a.shape, b.shape, c2.shape)\n",
    "print(c2)\n",
    "\n",
    "c1_ = c1.permute(0,2,1).unsqueeze(-1)\n",
    "print(c1_.shape,c2.shape)\n",
    "c = torch.cat([c1_, c2], dim=3)\n",
    "print('--------')\n",
    "print(c)\n",
    "print(c.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "the feature number of src and tgt must be equal to d_model",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [69]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m src \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand((\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m32\u001B[39m))\n\u001B[0;32m      3\u001B[0m tgt \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand((\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m512\u001B[39m))\n\u001B[1;32m----> 4\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mtransformer_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:143\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001B[0m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe batch number of src and tgt must be equal\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m src\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model \u001B[38;5;129;01mor\u001B[39;00m tgt\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model:\n\u001B[1;32m--> 143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe feature number of src and tgt must be equal to d_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    145\u001B[0m memory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(src, mask\u001B[38;5;241m=\u001B[39msrc_mask, src_key_padding_mask\u001B[38;5;241m=\u001B[39msrc_key_padding_mask)\n\u001B[0;32m    146\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(tgt, memory, tgt_mask\u001B[38;5;241m=\u001B[39mtgt_mask, memory_mask\u001B[38;5;241m=\u001B[39mmemory_mask,\n\u001B[0;32m    147\u001B[0m                       tgt_key_padding_mask\u001B[38;5;241m=\u001B[39mtgt_key_padding_mask,\n\u001B[0;32m    148\u001B[0m                       memory_key_padding_mask\u001B[38;5;241m=\u001B[39mmemory_key_padding_mask)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: the feature number of src and tgt must be equal to d_model"
     ]
    }
   ],
   "source": [
    "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 32, 32])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.rand((10, 32, 32))\n",
    "decoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=32, nhead=8, dropout=0.1),num_layers=2)\n",
    "decoder(src).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 32, 32])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = nn.TransformerEncoderLayer(d_model=32, nhead=8, dropout=0.1)\n",
    "encoder(src).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool2d((4,1))\n",
    "input = torch.randn(2,3,4,8)\n",
    "output = m(input).squeeze(-1)\n",
    "print(output.shape)\n",
    "output = nn.Linear(4,1)(output)\n",
    "print(output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 1])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(2,3,4,8)\n",
    "output = nn.Linear(8,1)(input)\n",
    "print(output.shape)\n",
    "output = nn.Linear(4,1)(output.squeeze(-1))\n",
    "print(output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.90453403 -0.90453403]\n",
      " [ 0.30151134  1.50755672]\n",
      " [ 1.50755672  0.30151134]\n",
      " [-0.90453403 -0.90453403]]\n",
      "[[1. 1.]\n",
      " [2. 3.]\n",
      " [3. 2.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[1,1], [2,3], [3,2], [1,1]]\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(data)\n",
    "print(scaled)\n",
    "\n",
    "# for inverse transformation\n",
    "inversed = scaler.inverse_transform(scaled)\n",
    "print(inversed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataset.TensorDataset at 0x20b140b4a60>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = utils.data.TensorDataset(src, src, src)\n",
    "data1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([False,  True,  True])"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logical_not(torch.tensor([0, 1, -10])==0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}